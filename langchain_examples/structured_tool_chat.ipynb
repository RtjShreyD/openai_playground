{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain.tools.playwright.utils import (\n",
    "    create_async_playwright_browser,\n",
    "    create_sync_playwright_browser, # A synchronous browser is available, though it isn't compatible with jupyter.\n",
    ")\n",
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_browser = create_async_playwright_browser()\n",
    "browser_toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = browser_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react-multi-input-json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import render_text_description_and_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.partial(\n",
    "    tools=render_text_description_and_args(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'agent_scratchpad'], partial_variables={'tools': 'click_element: Click on an element with the given CSS selector, args: {\\'selector\\': {\\'title\\': \\'Selector\\', \\'description\\': \\'CSS selector for the element to click\\', \\'type\\': \\'string\\'}}\\nnavigate_browser: Navigate a browser to the specified URL, args: {\\'url\\': {\\'title\\': \\'Url\\', \\'description\\': \\'url to navigate to\\', \\'type\\': \\'string\\'}}\\nprevious_webpage: Navigate back to the previous page in the browser history, args: {}\\nextract_text: Extract all the text on the current webpage, args: {}\\nextract_hyperlinks: Extract all hyperlinks on the current webpage, args: {\\'absolute_urls\\': {\\'title\\': \\'Absolute Urls\\', \\'description\\': \\'Return absolute URLs instead of relative URLs\\', \\'default\\': False, \\'type\\': \\'boolean\\'}}\\nget_elements: Retrieve elements in the current web page matching the given CSS selector, args: {\\'selector\\': {\\'title\\': \\'Selector\\', \\'description\\': \"CSS selector, such as \\'*\\', \\'div\\', \\'p\\', \\'a\\', #id, .classname\", \\'type\\': \\'string\\'}, \\'attributes\\': {\\'title\\': \\'Attributes\\', \\'description\\': \\'Set of attributes to retrieve for each element\\', \\'type\\': \\'array\\', \\'items\\': {\\'type\\': \\'string\\'}}}\\ncurrent_webpage: Returns the URL of the current page, args: {}', 'tool_names': 'click_element, navigate_browser, previous_webpage, extract_text, extract_hyperlinks, get_elements, current_webpage'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import configs\n",
    "from langchain import OpenAI \n",
    "OpenAI.api_key = configs.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "llm_with_stop = llm.bind(stop=[\"Observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_log_to_str(x['intermediate_steps']),\n",
    "} | prompt | llm_with_stop | JSONAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"navigate_browser\",\n",
      "  \"action_input\": {\n",
      "    \"url\": \"https://blog.langchain.dev\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mNavigating to https://blog.langchain.dev returned status code 200\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"extract_text\",\n",
      "  \"action_input\": {}\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3mLangChain Blog Skip to content LangChain Blog Home By LangChain Release Notes GitHub Docs Write with Us Sign in Subscribe Using a Knowledge Graph to implement a DevOps RAG application Editor's Note: This post was written in collaboration with the Neo4J team.\n",
      "\n",
      "RAG applications are all the rage at the moment. Everyone is building their 8 min read Featured Building Chat LangChain 7 min read Announcing LangChain Hub By LangChain 6 min read Using LangSmith to Support Fine-tuning By LangChain 9 min read Announcing LangSmith, a unified platform for debugging, testing, evaluating, and monitoring your LLM applications 8 min read Building (and Breaking) WebLangChain Important Links:\n",
      "\n",
      " * Hosted WebLangChain\n",
      " * Open-source code for WebLangChain\n",
      "\n",
      "\n",
      "Introduction\n",
      "\n",
      "One of the big shortcomings of LLMs is that they can only answer questions about data By LangChain 12 min read Handling PII data in LangChain This blog post was written by Francisco, a founder at Pampa Labs, who assists companies in developing LLM applications that are accurate and cost efficient. 5 min read Kay x Cybersyn x LangChain: Embedding SEC Filings for RAG Editor's Note: This post was written by the Kay team, in collaboration with Cybersyn. Financial data processing is hard. SEC Retriever on LangChain– Powered by 9 min read Bringing Free OSS Models to the Playground with Fireworks AI A year ago, the only real LLM people were using was OpenAI's GPT-3. Fast forward to now, and there are a multitude of models to 3 min read How \"Correct\" are LLM Evaluators? Summary:\n",
      "\n",
      " * We tested LangChain's LLM-assisted evaluators on common tasks to provide guidelines on how to best use them in your practice.\n",
      " * GPT-4 excels in accuracy 7 min read Building Chat LangChain Hosted: https://chat.langchain.com\n",
      "\n",
      "Repo: https://github.com/langchain-ai/chat-langchain\n",
      "\n",
      "\n",
      "Intro\n",
      "\n",
      "LangChain packs the power of large language models and an entire ecosystem of 7 min read Fine-tune your LLMs with LangSmith and Lilac In taking your LLM from prototype into production, many have turned to fine-tuning models to get more consistent and high-quality behavior in their applications. Services By LangChain 6 min read Timescale Vector x LangChain: Making PostgreSQL A Better Vector Database for AI Applications Editor's Note: This post was written in collaboration with the Timescale Vector team. Their integration with LangChain supports PostgreSQL as your vector database for faster 15 min read [Week of 9/18] LangChain Release Notes New in LangSmith\n",
      "\n",
      " * Org Support in LangChain Hub: share and collaborate on prompts across your team. Easily pull in organizationally-approved prompts into your LangChain code. By LangChain 4 min read LangChain and Scrimba Partner to help Web Devs become AI Engineers We’re excited to announce that we are partnering with Scrimba, a code-learning platform with over a million users. Through their interactive video format known 3 min read Eden AI x LangChain: Harnessing LLMs, Embeddings, and AI Editor's Note: This post was written in collaboration with the Eden AI team. We're really excited about Eden's approach to simplifying AI implementation so that 9 min read Peering Into the Soul of AI Decision-Making with LangSmith Editor's Note: This post was written by Paul Thomson from Commandbar. They've been awesome partners as they brought their application into production with LangSmith, and 10 min read Page 1 of 9 Load More Something went wrong with loading more posts Sign up © LangChain Blog 2023 - Powered by Ghost\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The LangChain Blog features various articles on topics such as implementing a DevOps RAG application using a Knowledge Graph, building chat applications with LangChain, handling PII data, embedding SEC filings for RAG, fine-tuning LLMs with LangSmith and Lilac, using Timescale Vector with LangChain, and more. The blog also includes release notes, partnerships, and updates from LangChain. The latest post on the blog is titled 'Peering Into the Soul of AI Decision-Making with LangSmith'.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Thought: Final response to the user\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The LangChain Blog features various articles on topics such as implementing a DevOps RAG application using a Knowledge Graph, building chat applications with LangChain, handling PII data, embedding SEC filings for RAG, fine-tuning LLMs with LangSmith and Lilac, using Timescale Vector with LangChain, and more. The blog also includes release notes, partnerships, and updates from LangChain. The latest post on the blog is titled 'Peering Into the Soul of AI Decision-Making with LangSmith'.\n"
     ]
    }
   ],
   "source": [
    "response = await agent_executor.ainvoke({\"input\": \"Browse to blog.langchain.dev and summarize the text, please.\"})\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0) # Also works well with Anthropic models\n",
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"navigate_browser\",\n",
      "  \"action_input\": {\n",
      "    \"url\": \"https://tecelit.hashnode.dev/iot-use-case-with-flask-and-http-part-2\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNavigating to https://tecelit.hashnode.dev/iot-use-case-with-flask-and-http-part-2 returned status code 200\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe webpage has been successfully loaded. Now I need to extract the text from the webpage to summarize it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"extract_text\",\n",
      "  \"action_input\": {}\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mIOT use-case with Flask and HTTP (Part 2) Follow Follow IOT use-case with Flask and HTTP (Part 2) TecElit Blog · May 1, 2021 · 7 min read In the previous tutorial we learnt about how HTTP can be used in IOT ie. for use-cases where a sensor needs to send data to the server at regular intervals. We learnt about a backend framework - Flask and how it helps us serving the API endpoints for GET and POST requests on the server. Then we discussed about a real-world problem, that occurs when we wish to update that data in real-time on a frontend(browser). This covers some depths of the Web Development world, but is necessary for an IOT developer to know, because as I said earlier an IOT developer must be that jack of all trades. NOTE: The problem we are discussing here is not only an IOT use case problem, it is a very general issue because in any Web system there could be a need to render real-time data on the frontend, it may be a dashboard or any simple website hardly matters the concept is always the same. Permalink Real-time update sensor values on Dashboard - The most efficient way Flask and mostly all backend frameworks have the ability to create and open socket connections, using a wrapper around the Websockets protocol Flask comes with a library called Flask-SSE SSE stands for Server Sent Events and is the best possible solution to the problem of updating real-time values on the Frontend. We will see it in practical, in a bit. In this post we are going to explore quite deeply how Flask_SSE works for realtime data streaming and how Javascript helps us here to grab that data. We will also discuss use-case scenario in which we can use AMQPS broker and Database such as redis for more efficiency. So let's get started. Permalink Server Sent Events with Flask Example Permalink Architecture What we will do now is create a very basic Flask application to render current date and time on the frontend in real-time. The Flask backend will stream the current date and time every second and a small Javascript will use that data and render it on the DOM. Now let's see this in action. Permalink Steps for Setting up the Application i. Activate the virtualenv created in Part-1. ii. Clone the repository code using git, if git is not install please install it, it's a simple installation for both Windows/Linux or MacOs, just Google search on how to install git on your OS. Assuming that git is installed run, git clone https://github.com/RtjShreyD/SSE-with-Flask.git . iii. After successful run of above command a new directory would have appeared named SSE-with-Flask . iv. Move into the cloned project by running, cd SSE-with-Flask and then install the requirements, run pip install -r requirements.txt . v. Once the requirements are installed, run python app.py to start the server. vi. Now open browser and goto localhost:5000 , what we see is that the current date and time is being updated in real-time on the frontend. The application here is using the concept of SSE in Flask and giving you real-time data on frontend. Basically, through SSE any data generated on the backend can be configured as SSE, which can be picked by Javascript's EventSource() function. Let's take a look at the code. We have a dir structure like below Copy Copy SSE- with -Flask\n",
      "        |\n",
      "        | -- templates/ |        |\n",
      "        |        | -- index.html |\n",
      "        | -- app.py | -- .gitignore | -- README.md | -- requirements.txt Now all the game is being played by app.py file and the index.html file. We should discuss about it, so examining the code of app.py , we have defined two routes - / and /stream , the /stream route runs a function named eventStream() which runs an infinite loop yielding the current date and time every 1 second. The data yielded by eventStream() function is returned as a response on the streamed socket connection. Next we have the index.html file which runs a Javascript on a <div> and connects to the /stream route on server through sockets internally, the connection and receiving streamed data from the connection is handled by the EventSource function in Javascript, which just manipulates the InnerHtml of the div element of the DOM as specified. This way data generated at the server side is send and updated on the client-side(frontend) in real-time. So this was a very basic example to demonstrate the concept of SSE, however we will be looking at a more typical example of SSE with an actual use-case next. In the next practical we will be looking at the same use-case as done in Part 1, where a server hosts an API endpoint for sensor data, an IOT device or any client can send data to server as POST requests and then the data sent is displayed in real-time on the frontend. This is a common use-case of any Dashboard not only just IOT. So let's see it in action. Permalink Architecture for Flask-SSE with redis for real world use-case Permalink Steps for Setting up Flask-SSE with redis for real world use-case If you have Docker and docker-compose installed you can follow the Run with Docker steps in the README.md after cloning this repository , else follow the steps below and don't get confused about Docker and related stuff for now. i. Install Redis, following the redis docs . ii. Clone the repository run, git clone https://github.com/RtjShreyD/iot-flask-redis-sse.git . iii. Create and Activate python virtual environment. iv. Install requirements run, pip install requirements.txt . v. Run Redis command in new terminal, redis-server . vi. Run App, python app.py and watch it on localhost:5000 . vii. Using Postman or any tool send POST request with header content-type --> text-plain and send any numerical string to route /therm/push . \n",
      "We can send a POST request from a new terminal as well by running, curl -X POST -H \"Content-Type: text/plain\" -d '{\"temperature\":56}' http://localhost:5000/therm/push . viii. The value should get updated immediately on frontend without reloading it. Repeat the above step with different data and you can see that update on frontend in real-time. ix. To stop the redis-server, press Ctrl+C or if the terminal got closed by mistake Redis would still be running, so run redis-cli shutdown to close it. Now that we have successfully established real-time communication between the server and client(browser) with and without redis, we should be wondering what is redis and what is it doing over here. So let's discuss it, Redis is actually a Database which supports key-value pair data storage as well as it is a messaging broker. Here using redis gives us two benefits - firstly that now our data shall be stored in a key-value data store, in a local file with .rdb extension and secondly it allows other systems/clients/servers which interact with our main server, say an analytics server also needs that streamed data to perform analytics on the data-history or any similar application. If we look at the architecture diagram carefully we see External Client or Server , this is the guy who is a 3rd party and needs to use the streamed data for any purpose, so redis serves this as well. However in heavy real-world systems, using separate Database instance and a separate messaging broker is preferred for various reasons. We will look deep into messaging brokers when we move forward to MQTT and AMQPS use-cases in IOT soon, then we may have a clear understanding of what to use when. NOTE: In this particular use-case which we have discussed with the practical here, we have just configured a redis database and for now we are not concerned about it's broker aspect at all, however if a 3rd party wants they can connect to the redis broker to use the data. Congratulations!! With this done, we have successfully learnt about how to create API endpoint for sensor data, how we can POST and GET data from the endpoint and how that data can be displayed and updated in real-time on the frontend. So we are done with the Application side part and now we have to deploy the application on cloud so that any our iot sensor or a client POST data to the server from anywhere. Once that is done we will look into how devices like Nodemcu or ESP32 can send real-sensor data to our server. So see you all in next post. Subscribe to my newsletter Read articles from TECELIT BLOG directly inside your inbox. Subscribe to the newsletter, and don't miss out. Subscribe Flask Framework Python Web Development iot realtime apps Written by TecElit Blog Follow Tec-Elit Development Solutions is a Learning, Prototyping & Development startup. More articles TecElit Blog IOT use-case with Flask and HTTP (Part 1) Hello developers and builders, we are back here with another simple IOT tutorial, where we will lear… TecElit Blog IOT and Web Protocols - A Theoretical background Introduction\n",
      "Welcome builders and developers to this complete IOT tutorial series. As we had discuss… TecElit Blog How web works ? - An Overview This is an introductory post for web developement, that's what I have been doing the most. In this p… Impressum IOT | Embedded Systems | Web Development | AI Visit our official website here Contact Us for consultancy or product/prototype development here ©2023 TECELIT BLOG Archive · Privacy policy · Terms Publish with Hashnode Powered by Hashnode - Home for tech writers and readers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe text on the webpage titled \"IOT use-case with Flask and HTTP (Part 2)\" discusses how HTTP can be used in IoT applications. It explains the use of Flask, a backend framework, to serve API endpoints for GET and POST requests on the server. The article also covers the problem of updating real-time data on the frontend and introduces Server Sent Events (SSE) as a solution. It provides an example of using Flask-SSE to stream real-time data to the frontend and discusses the use of AMQPS broker and databases like Redis for more efficiency. The article then walks through the steps to set up a basic Flask application that renders the current date and time on the frontend in real-time. It explains the code structure and the interaction between the backend and frontend using SSE. The article concludes by mentioning a more typical use-case of SSE with an API endpoint for sensor data and discusses the use of Redis as a key-value data store and messaging broker. It also mentions the possibility of deploying the application on the cloud and integrating IoT devices to send real-sensor data to the server.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The text on the webpage titled \"IOT use-case with Flask and HTTP (Part 2)\" discusses how HTTP can be used in IoT applications. It explains the use of Flask, a backend framework, to serve API endpoints for GET and POST requests on the server. The article also covers the problem of updating real-time data on the frontend and introduces Server Sent Events (SSE) as a solution. It provides an example of using Flask-SSE to stream real-time data to the frontend and discusses the use of AMQPS broker and databases like Redis for more efficiency. The article then walks through the steps to set up a basic Flask application that renders the current date and time on the frontend in real-time. It explains the code structure and the interaction between the backend and frontend using SSE. The article concludes by mentioning a more typical use-case of SSE with an API endpoint for sensor data and discusses the use of Redis as a key-value data store and messaging broker. It also mentions the possibility of deploying the application on the cloud and integrating IoT devices to send real-sensor data to the server.\n"
     ]
    }
   ],
   "source": [
    "response = await agent_chain.ainvoke({\"input\": \"Browse to https://tecelit.hashnode.dev/iot-use-case-with-flask-and-http-part-2 and summarize the text, please.\"})\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
